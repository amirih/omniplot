<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>omniplot.regressionplot API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>omniplot.regressionplot</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from typing import Union, Optional, Dict, List
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import pandas as pd
from matplotlib import cm
from matplotlib.lines import Line2D
from collections import defaultdict
import matplotlib.colors
import sys 
import matplotlib as mpl
from scipy.spatial.distance import pdist, squareform
from scipy.stats import zscore
from itertools import combinations

import os
script_dir = os.path.dirname( __file__ )
sys.path.append( script_dir )
from utils import _dendrogram_threshold, _radialtree2,_get_cluster_classes,_calc_curveture, _draw_ci_pi,_calc_r2,_ci_pi
import scipy.stats as stats

colormap_list=[&#34;nipy_spectral&#34;, &#34;terrain&#34;,&#34;tab20b&#34;,&#34;gist_rainbow&#34;,&#34;CMRmap&#34;,&#34;coolwarm&#34;,&#34;gnuplot&#34;,&#34;gist_stern&#34;,&#34;brg&#34;,&#34;rainbow&#34;]
plt.rcParams[&#39;font.family&#39;]= &#39;sans-serif&#39;
plt.rcParams[&#39;font.sans-serif&#39;] = [&#39;Arial&#39;]
plt.rcParams[&#39;svg.fonttype&#39;] = &#39;none&#39;
sns.set_theme()

def regression_single(df, 
                      x: str=&#34;&#34;,
                      y: str=&#34;&#34;, 
                      method: str=&#34;ransac&#34;,
                      category: str=&#34;&#34;, 
                      figsize: List[int]=[5,5],
                      show=False, ransac_param={&#34;max_trials&#34;:1000},
                      robust_param={}) -&gt; plt.Axes:
    &#34;&#34;&#34;
    Drawing a scatter plot with a single variable linear regression.  
    
    Parameters
    ----------
    df : pandas DataFrame
    
    x: str
        the column name of x axis. 
    y: str
        the column name of y axis. 

    method: str
        Method name for regression. Default: ransac
        Available methods: [&#34;ransac&#34;, 
                            &#34;robust&#34;,
                            &#34;lasso&#34;,&#34;elastic_net&#34;
                            ]
    figsize: list[int]
        figure size
    show : bool
        Whether or not to show the figure.
    
    Returns
    -------
    ax: plt.Axes
        axis object
    dict: dict
    z    dictionary containing estimated parameters
    Raises
    ------
    Notes
    -----
    References
    ----------
    See Also
    --------
    Examples
    --------
    &#34;&#34;&#34; 
    
    
    Y=df[y]
    _X=np.array(df[x]).reshape([-1,1])
    X=np.array(df[x])
    plotline_X = np.arange(X.min(), X.max()).reshape(-1, 1)
    n = X.shape[0]
    plt.rcParams.update({&#39;font.size&#39;: 14})
    fig, ax = plt.subplots(figsize=figsize)
    plt.subplots_adjust(left=0.15)
    if method==&#34;ransac&#34;:
        from sklearn.linear_model import RANSACRegressor
        
        
        
        fit_df=pd.DataFrame()
        ransac = RANSACRegressor(random_state=42,**ransac_param).fit(_X,Y)
        fit_df[&#34;ransac_regression&#34;] = ransac.predict(plotline_X)
        coef = ransac.estimator_.coef_[0]
        intercept=ransac.estimator_.intercept_
        inlier_mask = ransac.inlier_mask_
        outlier_mask = ~inlier_mask
        
                                # number of samples
        y_model=ransac.predict(_X)

        r2 = _calc_r2(X,Y)
        # mean squared error
        MSE = 1/n * np.sum( (Y - y_model)**2 )
        
        # to plot the adjusted model
        x_line = plotline_X.flatten()
        y_line = fit_df[&#34;ransac_regression&#34;]
         
        ci, pi, std_error=_ci_pi(X,Y,plotline_X.flatten(),y_model)
        sigma=std_error*(X.transpose() @ X)**(-0.5)
        #sigma=stats.t.sf(, df=X.shape[0]-2)
        coef_p=stats.t.sf(abs(ransac.estimator_.coef_[0]/sigma), df=X.shape[0]-2)
        ############### Ploting

        _draw_ci_pi(ax, ci, pi,x_line, y_line)
        sns.scatterplot(x=X[inlier_mask], y=Y[inlier_mask], color=&#34;blue&#34;, label=&#34;Inliers&#34;)
        sns.scatterplot(x=X[outlier_mask], y=Y[outlier_mask], color=&#34;red&#34;, label=&#34;Outliers&#34;)
        plt.xlabel(x)
        plt.ylabel(y)
        #print(r2, MSE,ransac_coef,ransac.estimator_.intercept_)
        plt.title(&#34;RANSAC regression, r2: {:.2f}, MSE: {:.2f}\ny = {:.2f} + {:.2f}x, coefficient p-value: {:.2E}&#34;.format(
            r2, MSE,coef,intercept,coef_p
            )
        )
        plt.plot(plotline_X.flatten(),fit_df[&#34;ransac_regression&#34;])
        if len(category)!=0:
            fig, ax=plt.subplots(figsize=figsize)
            plt.subplots_adjust(left=0.15)
            _draw_ci_pi(ax, ci, pi,x_line, y_line)
            sns.scatterplot(data=df,x=x, y=y, hue=category)
            
            plt.xlabel(x)
            plt.ylabel(y)
            #print(r2, MSE,ransac_coef,ransac.estimator_.intercept_)
            plt.title(&#34;RANSAC regression, r2: {:.2f}, MSE: {:.2f}\ny = {:.2f} + {:.2f}x, coefficient p-value: {:.2E}&#34;.format(
                r2, MSE,coef,intercept,coef_p
                )
            )
            plt.plot(plotline_X.flatten(),fit_df[&#34;ransac_regression&#34;])
    elif method==&#34;robust&#34;:
        import statsmodels.api as sm
        rlm_model = sm.RLM(Y, sm.add_constant(X),
        M=sm.robust.norms.HuberT(),**robust_param)
        rlm_results = rlm_model.fit()
        summary=rlm_results.summary()
        coef=rlm_results.params[1]
        intercept=rlm_results.params[0]
        intercept_p=rlm_results.pvalues[0]
        coef_p=rlm_results.pvalues[1]
        y_model=rlm_results.predict(sm.add_constant(X))
        r2 = _calc_r2(X,Y)
        x_line = plotline_X.flatten()
        y_line = rlm_results.predict(sm.add_constant(x_line))
        ci, pi=_ci_pi(X,Y,plotline_X.flatten(),y_model)
        MSE = 1/n * np.sum( (Y - y_model)**2 )

        _draw_ci_pi(ax, ci, pi,x_line, y_line)
        sns.scatterplot(data=df,x=x, y=y, color=&#34;blue&#34;)
        #print(r2, MSE,ransac_coef,ransac.estimator_.intercept_)
        plt.title(&#34;Robust linear regression, r2: {:.2f}, MSE: {:.2f}\ny = {:.2f} + {:.2f}x , p-values: coefficient {:.2f}, \
        intercept {:.2f}&#34;.format(
            r2, MSE,coef,intercept,coef_p,intercept_p
            )
        )
        plt.plot(plotline_X.flatten(),y_line)
        if len(category)!=0:
            fig, ax=plt.subplots(figsize=figsize)
            plt.subplots_adjust(left=0.15)
            _draw_ci_pi(ax, ci, pi,x_line, y_line)
            sns.scatterplot(data=df,x=x, y=y, hue=category)
            #print(r2, MSE,ransac_coef,ransac.estimator_.intercept_)
            plt.title(&#34;Robust linear regression, r2: {:.2f}, MSE: {:.2f}\ny = {:.2f} + {:.2f}x , p-values: coefficient {:.2f}, \
            intercept {:.2f}&#34;.format(
                r2, MSE,coef,intercept,coef_p,intercept_p
                )
            )
            plt.plot(plotline_X.flatten(),y_line)
    elif method==&#34;lasso&#34; or method==&#34;elastic_net&#34;:
        if method==&#34;lasso&#34;:
            method=&#34;sqrt_lasso&#34;
        import statsmodels.api as sm
        rlm_model = sm.OLS(Y, sm.add_constant(X))
        rlm_results = rlm_model.fit_regularized(method)
        print(vars(rlm_results))
        print(vars(rlm_results._results))
        #summary=rlm_results.summary()
        coef=rlm_results.params[1]
        intercept=rlm_results.params[0]
        y_model=rlm_results.predict(sm.add_constant(X))
        r2 = _calc_r2(X,Y)
        x_line = plotline_X.flatten()
        y_line = rlm_results.predict(sm.add_constant(x_line))
        ci, pi, std_error=_ci_pi(X,Y,plotline_X.flatten(),y_model)
        sigma=std_error*(X.transpose() @ X)**(-0.5)
        print(sigma,coef )
        coef_p=stats.t.sf(abs(coef/sigma), df=X.shape[0]-2)
        MSE = 1/n * np.sum( (Y - y_model)**2 )

        _draw_ci_pi(ax, ci, pi,x_line, y_line)   
        sns.scatterplot(data=df,x=x, y=y, color=&#34;blue&#34;)
        #print(r2, MSE,ransac_coef,ransac.estimator_.intercept_)
        plt.title(&#34;OLS ({}), r2: {:.2f}, MSE: {:.2f}\ny = {:.2f} + {:.2f}x, coefficient p-value: {:.2E}&#34;.format(method,
            r2, MSE,coef,intercept,coef_p
            )
        )
        plt.plot(plotline_X.flatten(),y_line)
        if len(category)!=0:
            fig, ax=plt.subplots(figsize=figsize)
            plt.subplots_adjust(left=0.15)
            _draw_ci_pi(ax, ci, pi,x_line, y_line)
            sns.scatterplot(data=df,x=x, y=y, color=&#34;blue&#34;,hue=category)
            #print(r2, MSE,ransac_coef,ransac.estimator_.intercept_)
            plt.title(&#34;OLS ({}), r2: {:.2f}, MSE: {:.2f}\ny = {:.2f} + {:.2f}x, coefficient p-value: {:.2E}&#34;.format(method,
                r2, MSE,coef,intercept,coef_p
                )
            )
            plt.plot(plotline_X.flatten(),y_line)
    return ax, {&#34;coefficient&#34;:coef,&#34;intercept&#34;:intercept,&#34;coefficient_pval&#34;:coef_p, &#34;r2&#34;:r2}

def regression_single_polynomial(df: pd.DataFrame, 
                      x: str,
                      y: str, 
                      method: str=&#34;ransac&#34;,
                      category: str=&#34;&#34;, 
                      figsize: List[int]=[5,5],
                      show=False, ransac_param={&#34;max_trials&#34;:1000},
                      robust_param={},
                      xunit: str=&#34;&#34;,
                      yunit: str=&#34;&#34;,
                      title: str=&#34;&#34;,
                      random_state: int=42,ax: Optional[plt.Axes]=None,
                      save: str=&#34;&#34;) -&gt; Dict:
    &#34;&#34;&#34;
    Drawing a scatter plot with a single variable linear regression.  
    
    Parameters
    ----------
    df : pandas DataFrame
    
    x: str
        the column name of x axis. 
    y: str
        the column name of y axis. 

    method: str
        Method name for regression. Default: ransac
        Available methods: [&#34;ransac&#34;, 
                            &#34;robust&#34;,
                            &#34;lasso&#34;,&#34;elastic_net&#34;
                            ]
    figsize: list[int]
        figure size
    show : bool
        Whether or not to show the figure.
    
    Returns
    -------
    dict: dict {&#34;axes&#34;:ax, &#34;coefficient&#34;:coef,&#34;intercept&#34;:intercept,&#34;coefficient_pval&#34;:coef_p, &#34;r2&#34;:r2, &#34;fitted_model&#34;:fitted_model}
    
        fitted_model:
            this can be used like: y_predict=fitted_model.predict(_X)
    Raises
    ------
    Notes
    -----
    References
    ----------
    See Also
    --------
    Examples
    --------
    &#34;&#34;&#34; 
    pass


def regression_multivariable():
    pass

def regression_multivariable_nonlinear():
    pass

def regression_glm():
    pass</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="omniplot.regressionplot.regression_glm"><code class="name flex">
<span>def <span class="ident">regression_glm</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def regression_glm():
    pass</code></pre>
</details>
</dd>
<dt id="omniplot.regressionplot.regression_multivariable"><code class="name flex">
<span>def <span class="ident">regression_multivariable</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def regression_multivariable():
    pass</code></pre>
</details>
</dd>
<dt id="omniplot.regressionplot.regression_multivariable_nonlinear"><code class="name flex">
<span>def <span class="ident">regression_multivariable_nonlinear</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def regression_multivariable_nonlinear():
    pass</code></pre>
</details>
</dd>
<dt id="omniplot.regressionplot.regression_single"><code class="name flex">
<span>def <span class="ident">regression_single</span></span>(<span>df, x: str = '', y: str = '', method: str = 'ransac', category: str = '', figsize: List[int] = [5, 5], show=False, ransac_param={'max_trials': 1000}, robust_param={}) ‑> matplotlib.axes._axes.Axes</span>
</code></dt>
<dd>
<div class="desc"><p>Drawing a scatter plot with a single variable linear regression.
</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>df</code></strong> :&ensp;<code>pandas DataFrame</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>x</code></strong> :&ensp;<code>str</code></dt>
<dd>the column name of x axis.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>str</code></dt>
<dd>the column name of y axis.</dd>
<dt><strong><code>method</code></strong> :&ensp;<code>str</code></dt>
<dd>Method name for regression. Default: ransac
Available methods: ["ransac",
"robust",
"lasso","elastic_net"
]</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>list[int]</code></dt>
<dd>figure size</dd>
<dt><strong><code>show</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether or not to show the figure.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ax</code></strong> :&ensp;<code>plt.Axes</code></dt>
<dd>axis object</dd>
<dt><strong><code>dict</code></strong> :&ensp;<code>dict</code></dt>
<dd>&nbsp;</dd>
<dt><code>z
dictionary containing estimated parameters</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="raises">Raises</h2>
<h2 id="notes">Notes</h2>
<h2 id="references">References</h2>
<h2 id="see-also">See Also</h2>
<h2 id="examples">Examples</h2></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def regression_single(df, 
                      x: str=&#34;&#34;,
                      y: str=&#34;&#34;, 
                      method: str=&#34;ransac&#34;,
                      category: str=&#34;&#34;, 
                      figsize: List[int]=[5,5],
                      show=False, ransac_param={&#34;max_trials&#34;:1000},
                      robust_param={}) -&gt; plt.Axes:
    &#34;&#34;&#34;
    Drawing a scatter plot with a single variable linear regression.  
    
    Parameters
    ----------
    df : pandas DataFrame
    
    x: str
        the column name of x axis. 
    y: str
        the column name of y axis. 

    method: str
        Method name for regression. Default: ransac
        Available methods: [&#34;ransac&#34;, 
                            &#34;robust&#34;,
                            &#34;lasso&#34;,&#34;elastic_net&#34;
                            ]
    figsize: list[int]
        figure size
    show : bool
        Whether or not to show the figure.
    
    Returns
    -------
    ax: plt.Axes
        axis object
    dict: dict
    z    dictionary containing estimated parameters
    Raises
    ------
    Notes
    -----
    References
    ----------
    See Also
    --------
    Examples
    --------
    &#34;&#34;&#34; 
    
    
    Y=df[y]
    _X=np.array(df[x]).reshape([-1,1])
    X=np.array(df[x])
    plotline_X = np.arange(X.min(), X.max()).reshape(-1, 1)
    n = X.shape[0]
    plt.rcParams.update({&#39;font.size&#39;: 14})
    fig, ax = plt.subplots(figsize=figsize)
    plt.subplots_adjust(left=0.15)
    if method==&#34;ransac&#34;:
        from sklearn.linear_model import RANSACRegressor
        
        
        
        fit_df=pd.DataFrame()
        ransac = RANSACRegressor(random_state=42,**ransac_param).fit(_X,Y)
        fit_df[&#34;ransac_regression&#34;] = ransac.predict(plotline_X)
        coef = ransac.estimator_.coef_[0]
        intercept=ransac.estimator_.intercept_
        inlier_mask = ransac.inlier_mask_
        outlier_mask = ~inlier_mask
        
                                # number of samples
        y_model=ransac.predict(_X)

        r2 = _calc_r2(X,Y)
        # mean squared error
        MSE = 1/n * np.sum( (Y - y_model)**2 )
        
        # to plot the adjusted model
        x_line = plotline_X.flatten()
        y_line = fit_df[&#34;ransac_regression&#34;]
         
        ci, pi, std_error=_ci_pi(X,Y,plotline_X.flatten(),y_model)
        sigma=std_error*(X.transpose() @ X)**(-0.5)
        #sigma=stats.t.sf(, df=X.shape[0]-2)
        coef_p=stats.t.sf(abs(ransac.estimator_.coef_[0]/sigma), df=X.shape[0]-2)
        ############### Ploting

        _draw_ci_pi(ax, ci, pi,x_line, y_line)
        sns.scatterplot(x=X[inlier_mask], y=Y[inlier_mask], color=&#34;blue&#34;, label=&#34;Inliers&#34;)
        sns.scatterplot(x=X[outlier_mask], y=Y[outlier_mask], color=&#34;red&#34;, label=&#34;Outliers&#34;)
        plt.xlabel(x)
        plt.ylabel(y)
        #print(r2, MSE,ransac_coef,ransac.estimator_.intercept_)
        plt.title(&#34;RANSAC regression, r2: {:.2f}, MSE: {:.2f}\ny = {:.2f} + {:.2f}x, coefficient p-value: {:.2E}&#34;.format(
            r2, MSE,coef,intercept,coef_p
            )
        )
        plt.plot(plotline_X.flatten(),fit_df[&#34;ransac_regression&#34;])
        if len(category)!=0:
            fig, ax=plt.subplots(figsize=figsize)
            plt.subplots_adjust(left=0.15)
            _draw_ci_pi(ax, ci, pi,x_line, y_line)
            sns.scatterplot(data=df,x=x, y=y, hue=category)
            
            plt.xlabel(x)
            plt.ylabel(y)
            #print(r2, MSE,ransac_coef,ransac.estimator_.intercept_)
            plt.title(&#34;RANSAC regression, r2: {:.2f}, MSE: {:.2f}\ny = {:.2f} + {:.2f}x, coefficient p-value: {:.2E}&#34;.format(
                r2, MSE,coef,intercept,coef_p
                )
            )
            plt.plot(plotline_X.flatten(),fit_df[&#34;ransac_regression&#34;])
    elif method==&#34;robust&#34;:
        import statsmodels.api as sm
        rlm_model = sm.RLM(Y, sm.add_constant(X),
        M=sm.robust.norms.HuberT(),**robust_param)
        rlm_results = rlm_model.fit()
        summary=rlm_results.summary()
        coef=rlm_results.params[1]
        intercept=rlm_results.params[0]
        intercept_p=rlm_results.pvalues[0]
        coef_p=rlm_results.pvalues[1]
        y_model=rlm_results.predict(sm.add_constant(X))
        r2 = _calc_r2(X,Y)
        x_line = plotline_X.flatten()
        y_line = rlm_results.predict(sm.add_constant(x_line))
        ci, pi=_ci_pi(X,Y,plotline_X.flatten(),y_model)
        MSE = 1/n * np.sum( (Y - y_model)**2 )

        _draw_ci_pi(ax, ci, pi,x_line, y_line)
        sns.scatterplot(data=df,x=x, y=y, color=&#34;blue&#34;)
        #print(r2, MSE,ransac_coef,ransac.estimator_.intercept_)
        plt.title(&#34;Robust linear regression, r2: {:.2f}, MSE: {:.2f}\ny = {:.2f} + {:.2f}x , p-values: coefficient {:.2f}, \
        intercept {:.2f}&#34;.format(
            r2, MSE,coef,intercept,coef_p,intercept_p
            )
        )
        plt.plot(plotline_X.flatten(),y_line)
        if len(category)!=0:
            fig, ax=plt.subplots(figsize=figsize)
            plt.subplots_adjust(left=0.15)
            _draw_ci_pi(ax, ci, pi,x_line, y_line)
            sns.scatterplot(data=df,x=x, y=y, hue=category)
            #print(r2, MSE,ransac_coef,ransac.estimator_.intercept_)
            plt.title(&#34;Robust linear regression, r2: {:.2f}, MSE: {:.2f}\ny = {:.2f} + {:.2f}x , p-values: coefficient {:.2f}, \
            intercept {:.2f}&#34;.format(
                r2, MSE,coef,intercept,coef_p,intercept_p
                )
            )
            plt.plot(plotline_X.flatten(),y_line)
    elif method==&#34;lasso&#34; or method==&#34;elastic_net&#34;:
        if method==&#34;lasso&#34;:
            method=&#34;sqrt_lasso&#34;
        import statsmodels.api as sm
        rlm_model = sm.OLS(Y, sm.add_constant(X))
        rlm_results = rlm_model.fit_regularized(method)
        print(vars(rlm_results))
        print(vars(rlm_results._results))
        #summary=rlm_results.summary()
        coef=rlm_results.params[1]
        intercept=rlm_results.params[0]
        y_model=rlm_results.predict(sm.add_constant(X))
        r2 = _calc_r2(X,Y)
        x_line = plotline_X.flatten()
        y_line = rlm_results.predict(sm.add_constant(x_line))
        ci, pi, std_error=_ci_pi(X,Y,plotline_X.flatten(),y_model)
        sigma=std_error*(X.transpose() @ X)**(-0.5)
        print(sigma,coef )
        coef_p=stats.t.sf(abs(coef/sigma), df=X.shape[0]-2)
        MSE = 1/n * np.sum( (Y - y_model)**2 )

        _draw_ci_pi(ax, ci, pi,x_line, y_line)   
        sns.scatterplot(data=df,x=x, y=y, color=&#34;blue&#34;)
        #print(r2, MSE,ransac_coef,ransac.estimator_.intercept_)
        plt.title(&#34;OLS ({}), r2: {:.2f}, MSE: {:.2f}\ny = {:.2f} + {:.2f}x, coefficient p-value: {:.2E}&#34;.format(method,
            r2, MSE,coef,intercept,coef_p
            )
        )
        plt.plot(plotline_X.flatten(),y_line)
        if len(category)!=0:
            fig, ax=plt.subplots(figsize=figsize)
            plt.subplots_adjust(left=0.15)
            _draw_ci_pi(ax, ci, pi,x_line, y_line)
            sns.scatterplot(data=df,x=x, y=y, color=&#34;blue&#34;,hue=category)
            #print(r2, MSE,ransac_coef,ransac.estimator_.intercept_)
            plt.title(&#34;OLS ({}), r2: {:.2f}, MSE: {:.2f}\ny = {:.2f} + {:.2f}x, coefficient p-value: {:.2E}&#34;.format(method,
                r2, MSE,coef,intercept,coef_p
                )
            )
            plt.plot(plotline_X.flatten(),y_line)
    return ax, {&#34;coefficient&#34;:coef,&#34;intercept&#34;:intercept,&#34;coefficient_pval&#34;:coef_p, &#34;r2&#34;:r2}</code></pre>
</details>
</dd>
<dt id="omniplot.regressionplot.regression_single_polynomial"><code class="name flex">
<span>def <span class="ident">regression_single_polynomial</span></span>(<span>df: pandas.core.frame.DataFrame, x: str, y: str, method: str = 'ransac', category: str = '', figsize: List[int] = [5, 5], show=False, ransac_param={'max_trials': 1000}, robust_param={}, xunit: str = '', yunit: str = '', title: str = '', random_state: int = 42, ax: Optional[matplotlib.axes._axes.Axes] = None, save: str = '') ‑> Dict[~KT, ~VT]</span>
</code></dt>
<dd>
<div class="desc"><p>Drawing a scatter plot with a single variable linear regression.
</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>df</code></strong> :&ensp;<code>pandas DataFrame</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>x</code></strong> :&ensp;<code>str</code></dt>
<dd>the column name of x axis.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>str</code></dt>
<dd>the column name of y axis.</dd>
<dt><strong><code>method</code></strong> :&ensp;<code>str</code></dt>
<dd>Method name for regression. Default: ransac
Available methods: ["ransac",
"robust",
"lasso","elastic_net"
]</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>list[int]</code></dt>
<dd>figure size</dd>
<dt><strong><code>show</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether or not to show the figure.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>dict</code></strong> :&ensp;<code>dict {"axes":ax, "coefficient":coef,"intercept":intercept,"coefficient_pval":coef_p, "r2":r2, "fitted_model":fitted_model}</code></dt>
<dd>fitted_model:
this can be used like: y_predict=fitted_model.predict(_X)</dd>
</dl>
<h2 id="raises">Raises</h2>
<h2 id="notes">Notes</h2>
<h2 id="references">References</h2>
<h2 id="see-also">See Also</h2>
<h2 id="examples">Examples</h2></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def regression_single_polynomial(df: pd.DataFrame, 
                      x: str,
                      y: str, 
                      method: str=&#34;ransac&#34;,
                      category: str=&#34;&#34;, 
                      figsize: List[int]=[5,5],
                      show=False, ransac_param={&#34;max_trials&#34;:1000},
                      robust_param={},
                      xunit: str=&#34;&#34;,
                      yunit: str=&#34;&#34;,
                      title: str=&#34;&#34;,
                      random_state: int=42,ax: Optional[plt.Axes]=None,
                      save: str=&#34;&#34;) -&gt; Dict:
    &#34;&#34;&#34;
    Drawing a scatter plot with a single variable linear regression.  
    
    Parameters
    ----------
    df : pandas DataFrame
    
    x: str
        the column name of x axis. 
    y: str
        the column name of y axis. 

    method: str
        Method name for regression. Default: ransac
        Available methods: [&#34;ransac&#34;, 
                            &#34;robust&#34;,
                            &#34;lasso&#34;,&#34;elastic_net&#34;
                            ]
    figsize: list[int]
        figure size
    show : bool
        Whether or not to show the figure.
    
    Returns
    -------
    dict: dict {&#34;axes&#34;:ax, &#34;coefficient&#34;:coef,&#34;intercept&#34;:intercept,&#34;coefficient_pval&#34;:coef_p, &#34;r2&#34;:r2, &#34;fitted_model&#34;:fitted_model}
    
        fitted_model:
            this can be used like: y_predict=fitted_model.predict(_X)
    Raises
    ------
    Notes
    -----
    References
    ----------
    See Also
    --------
    Examples
    --------
    &#34;&#34;&#34; 
    pass</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="omniplot" href="index.html">omniplot</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="omniplot.regressionplot.regression_glm" href="#omniplot.regressionplot.regression_glm">regression_glm</a></code></li>
<li><code><a title="omniplot.regressionplot.regression_multivariable" href="#omniplot.regressionplot.regression_multivariable">regression_multivariable</a></code></li>
<li><code><a title="omniplot.regressionplot.regression_multivariable_nonlinear" href="#omniplot.regressionplot.regression_multivariable_nonlinear">regression_multivariable_nonlinear</a></code></li>
<li><code><a title="omniplot.regressionplot.regression_single" href="#omniplot.regressionplot.regression_single">regression_single</a></code></li>
<li><code><a title="omniplot.regressionplot.regression_single_polynomial" href="#omniplot.regressionplot.regression_single_polynomial">regression_single_polynomial</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>